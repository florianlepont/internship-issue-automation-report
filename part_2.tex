\chapter{Automatisation du processus d'investigation}
\label{Automatisation du processus d'investigation}
\thispagestyle{fancy}
Lorsqu'une \emph{error name} est révélée durant le Filtering test, de nombreuses données sont enregistrées dans un fichier journal (que l'on retrouve plus souvent sous le terme anglais de fichier "log".) Une analyse poussée de ces informations permet de déterminer la \emph{root cause} liée à l'\emph{error name} (partie \ref{Introduction:Expression du besoin:Hiérarchisation des erreurs}). Afin d'automatiser ce processus d'analyse, on s'appuie sur l'utilisation d'algorithmes d'apprentissage automatique. 

\section{Architecture High Level du système proposé}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé}
L'architecture haut niveau de la solution que l'on propose est composée de deux couches: une couche \emph{root cause} et une couche \emph{error name}.
\begin{description}
	\item [Couche root cause] La couche \emph{root cause} permet de détecter la présence d'une \emph{root cause} dans le fichier log que l'on analyse. Il s'agit d'un algorithme d'apprentissage automatique entraîné à effectuer cette tâche.
	\item [Couche error name] La couche \emph{error name} est constituée d'un ensemble de couches \emph{root cause} de telle manière que lorsqu'un fichier log est mis en entrée du système, l'ensemble des couches \emph{root cause} sont activées. Ainsi, le système recherche la présence de chaque \emph{root cause} connue dans l'exemple étudié. On dit que les \emph{root causes} sont liées à l'\emph{error name}. On obtient en sortie de la couche \emph{error name} le nom de la \emph{root cause} ayant la plus forte probabilité d'avoir été reconnue.
\end{description} 

\subsubsection{Exemple de mise en place  d'une couche error name et de ses couches root cause}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Exemple de mise en place  d'une couche error name et de ses couches root cause}
Afin d'exposer de manière concrète le fonctionnement de l'architecture haut niveau de la solution proposée, on soumet un exemple de mise en place d'une architecture de détection et son utilisation. \\

\paragraph{Mise en place du système de détection d'une root cause}
On souhaite dans un premier temps mettre en place l'architecture permettant de détecter la cause (\emph{root cause}) ayant entrainé la chute du robot lors du Filtering test (\emph{error name}). Cette étape consiste à créer les couches \emph{root cause}, i.e. entrainer différents algorithmes d'apprentissage automatique à reconnaître la \emph{root cause} pour laquelle ils ont été créés (figure \ref{fig:Creation des couches root cause}). Afin d'entraîner ces couches, on utilise les données utiles à chaque \emph{root cause}, contenues dans le fichier log généré lors de la chute d'un robot durant le Filtering Test. Par exemple, dans le cas de la \emph{root cause} "frottement des freins de la hanche", on utilisera les données "valeurs du senseur de la hanche" et "valeurs de l'actuateur de la hanche". Ces deux éléments correspondent aux features de notre système d'apprentissage (c.f. partie \ref{Le Machine Learning: Généralités sur le Machine Learning: Définition et principe général:Lexique}). L'ensemble de ces couches \emph{root cause} sont liées une couche \emph{error name}, Ici la chute d'un robot.

\begin{figure}[h]
	\centering\includegraphics[height=7cm]{images/synoptique_root.png}
	\caption[Création des couches root cause]{Synoptique haut niveau de la création des couches \emph{root cause}. Les couches \emph{root cause} correspondent à des algorithmes d'apprentissage automatique que l'on entraîne à détecter la \emph{root cause} à laquelle ils sont associés. Par exemple, créer la couche \emph{root cause} "frottement du frein de la hanche" revient à entraîner un algorithme d'apprentissage de type SVM, à partir des valeurs senseurs et actuateurs de la hanche des fichiers logs.}
	\label{fig:Creation des couches root cause}
\end{figure}

\paragraph{Utilisation du système de détection d'une root cause}
Une fois nos différentes couches \emph{root cause} créées, on souhaite utiliser notre système pour détecter la cause ayant entrainé la chute d'un robot (c.f. figure \ref{fig:utilisation de la couche error name}). Pour cela, on place à l'entrée de notre couche \emph{error name} le fichier log que l'on souhaite analyser. Chaque couche \emph{root cause} extrait de ce fichier les features qui lui sont liées (e.g. la \emph{root cause} "frottement des freins de la hanche" est liée aux features senseurs et actuateurs de la hanche). L'algorithme SVM de chaque couche \emph{root cause} va alors émettre une décision quant à la présence ou non de leur \emph{root cause} dans le fichier log. Cette décision correspond à la probabilité que la \emph{ root cause} ait été détectée (en \%). La couche \emph{root cause} ayant la probabilité la plus élevée en sortie est considérée comme la \emph{root cause} ayant entrainé l'\emph{error name},  ici la chute du robot) 

\begin{figure}[h]
	\centering\includegraphics[width=12cm]{images/synoptique_error.png}
	\caption[Utilisation de la couche error name]{Synoptique haut niveau de l'utilisation de la couche \emph{error name}. La couche \emph{error name} contient plusieurs couches \emph{root cause} (on dit qu'elles sont liées). On met en entrée du système le fichier log que l'on souhaite analyser, puis chaque couche \emph{root cause} va détecter la présence de sa \emph{root cause}. On obtient en sortie de la couche \emph{error name} la \emph{root cause}  ayant eu la plus forte probabilité d'avoir été reconnue.}
	\label{fig:utilisation de la couche error name}
\end{figure}

Chaque couche \emph{root cause} peut être considérée comme un système d'apprentissage à part entière. Le schéma fonctionnel d'une \emph{root cause} (cf. figure 	\ref{fig:Synoptique d'une couche root cause}) reprend la même structure que celui du Machine Learning (c.f. \ref{fig:Schéma fonctionnel haut niveau du Machine Learning}). En effet, chaque \emph{root cause} est constituée d'une instance de l'algorithme SVM. Dans la suite de notre étude de l'architecture haut niveau, on s'intéressera plus particulièrement  au fonctionnement de la couche \emph{root cause}, celle-ci contenant l'ensemble du traitement et de l'analyse des données.

\begin{figure}[h]
	\centering\includegraphics[height=7cm]{images/exemple_root.png}
	\caption[Synoptique d'une couche root cause]{Synoptique d'une couche \emph{root cause}. Il correspond à celui du Machine Learning car chaque couche \emph{root cause} est en réalité un algorithme d'apprentissage supervisé SVM que l'on entraine à détecter une \emph{root cause} particulière.}
	\label{fig:Synoptique d'une couche root cause}
\end{figure}

\subsection{Les exemples}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples}
Les exemples sont les éléments permettant d'entraîner un algorithme d'apprentissage automatique (c.f. partie \ref{Le Machine Learning: Généralités sur le Machine Learning: Les données}). Dans le cadre de la résolution de notre problématique, ils correspondent aux données générées et enregistrées dans le fichier log lorsqu'une erreur (\emph{error name}) est détectée durant le Filtering Test.

\subsubsection{Structure du fichier log}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Structure du fichier log}
Le fichier log renferme un ensemble de données enregistrées lors de la détection d'une erreur durant le Filtering Test. Elles correspondent aux "rythmes vitaux" du robot. Le fichier contient par exemple l'évolution temporelle des différents actuateurs et senseurs de Pepper, la température de différentes pièces mécaniques, etc. Dans le cadre de l'entraînement de l'algorithme du Machine Learning (SVM), chacune de ces constantes correspond à une feature  (c.f. partie  \ref{Le Machine Learning: Généralités sur le Machine Learning: Définition et principe général:Lexique}). Soit le tableau \ref {tab: Extrait du contenu d'un fichier log}, un extrait du contenu d'un fichier log:

\begin{equation}
\begin{blockarray}{ccccccc}
\begin{block}{c[cccccc]}
features & X_1 & X_2 & X_3 & X_4 &  X_5 & X_6 \\
t_0 & -0,404 & 0,64 & -0,023 & -0,04 & -0,008 & -0,007 \\
t_1 & -0,404 & 0,64 & -0,029 & -0,038 & -0,006 & -0,006 \\
t_3 & -0,404 & 0,576 & -0,029 & -0,033 & -0,008 & -0,012 \\
t_4 & -0,402 & 0,544 & -0,029 & -0,027 & -0,012 & -0,022 \\
t_5 & -0,401 & 0,448 & -0,029 & -0,027 & -0,015 & -0,029 \\
t_6 & -0,401 & 0,448 & -0,023 & -0,029 & -0,017 & -0,031 \\
t_7 & -0,408 & 0,096 & -0,021 & -0,031 & -0,015 & -0,032 \\
t_8 & -0,444 & 0,096 & -0,021 & -0,032 & -0,015 & 0,035 \\
t_9 & -0,486 & 0,096 & -0,021 & -0,033 & -0,017 & -0,039 \\
t_{10} & -0,523 & 0,128 & -0,021 & -0,033 & -0,018 & -0,043 \\
t_n & ... & ... & ... & ... & ... & ... \\
\end{block}
\end{blockarray}
\label {tab: Extrait du contenu d'un fichier log}
\end{equation}

Avec :
\begin{itemize}
	\item $X_1$ = HeadPitchPositionActuatorValue
	\item $X_2$ = HeadPitchElectricCurrentSensorValue
	\item $X_3$ = ipPitchPositionSensorValue
	\item $X_4$ = HipPitchPositionActuatorValue
	\item $X_5$ = KneePitchPositionSensorValue
	\item $ X_6$ = KneePitchPositionActuatorValue
\end{itemize}

Le fichier log, représenté par le tableau \ref {tab: Extrait du contenu d'un fichier log}, correspond à un exemple de la base de données qui sert à entrainer chacun de nos algorithmes. \\ 
A chaque colonne du tableau correspond une feature. Chacune des lignes est la valeur des features à un instant t (une ligne ne correspond pas à un exemple !). 

\subsubsection{Structure de la base de données d'exemples}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Structure de la base de données d'exemples}
La base de donnée est composée de plusieurs exemples qui correspondent à des fichiers logs. Par exemple, dans le cadre de la construction de couche \emph{error name} de la chute d'un robot, la base de donnée sera constituée de fichiers logs générés par plusieurs cas de chutes sur différents robots. On peut représenter la structure des données de la base de données par le tableau \ref {tab: Structure de la base de données d'exemples pour l'entrainement du SVM}

\begin{equation}
\begin{blockarray}{ccccccc}
\begin{block}{c[cccccc]}
features & HeadPitchPositionActuatorValue & HeadPitchElectricCurrentSensorValue & HipPitchPositionSensorValue & HipPitchPositionActuatorValue &  KneePitchPositionSensorValue & KneePitchPositionActuatorValue \\
exemple_0 & log_0 [HeadPitchPositionActuatorValue] & log_0 [HeadPitchElectricCurrentSensorValue] & log_0 [HipPitchPositionSensorValue]& log_0 [HipPitchPositionActuatorValue] & log_0 [KneePitchPositionSensorValue] & log_0 [KneePitchPositionActuatorValue]  \\
exemple_1 & log_1 [HeadPitchPositionActuatorValue] & log_1 [HeadPitchElectricCurrentSensorValue] & log_1 [HipPitchPositionSensorValue]& log_1 [HipPitchPositionActuatorValue] & log_1 [KneePitchPositionSensorValue] & log_1 [KneePitchPositionActuatorValue]  \\
exemple_2 & log_2 [HeadPitchPositionActuatorValue] & log_2 [HeadPitchElectricCurrentSensorValue] & log_2 [HipPitchPositionSensorValue]& log_2 [HipPitchPositionActuatorValue] & log_2 [KneePitchPositionSensorValue] & log_2 [KneePitchPositionActuatorValue]  \\
exemple_3 & log_3 [HeadPitchPositionActuatorValue] & log_3 [HeadPitchElectricCurrentSensorValue] & log_3 [HipPitchPositionSensorValue]& log_3 [HipPitchPositionActuatorValue] & log_3 [KneePitchPositionSensorValue] & log_3 [KneePitchPositionActuatorValue]  \\
exemple_4 & log_4 [HeadPitchPositionActuatorValue] & log_4 [HeadPitchElectricCurrentSensorValue] & log_4 [HipPitchPositionSensorValue]& log_4 [HipPitchPositionActuatorValue] & log_4 [KneePitchPositionSensorValue] & log_4 [KneePitchPositionActuatorValue]  \\
exemple_4 & log_4 [HeadPitchPositionActuatorValue] & log_n [HeadPitchElectricCurrentSensorValue] & log_n [HipPitchPositionSensorValue]& log_n [HipPitchPositionActuatorValue] & log_n [KneePitchPositionSensorValue] & log_n [KneePitchPositionActuatorValue]  \\
\end{block}
\end{blockarray}
\label {tab: Structure de la base de données d'exemples pour l'entrainement du SVM}
\end{equation}

Tout comme la structure d'un fichier log (\ref{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Structure du fichier log}), chaque colonne correspond à une feature. Chaque ligne de ce tableau représente un exemple et correspond à un fichier log en particulier. Cela signifie  que chaque ligne du tableau représente le contenu d'un fichier log, comme présenté dans le tableau \ref {tab: Extrait du contenu d'un fichier log}.

\subsubsection{Construction d'une couche root cause à partir de la base de données d'exemples}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Construction d'une couche root cause à partir de la base de données d'exemples}
Lorsque l'on veut construire une nouvelle couche root cause, i.e. entraîner un nouvel algorithme d'apprentissage pour détecter la présence d'une root cause particulière dans le fichier log, on va sélectionner uniquement les features de la base de données d'exemples liées à la root cause. Par exemple, si on veut créer une nouvelle couche root cause "frottement des freins de la hanche" (lié à l'error name chute du robot), on n'utilisera que les features "HipPitchPositionSensorValue" et "HipPitchPositionActuatorValue" de notre base de données.

\subsection{Parallèle avec l'exemple de la prévision saisonnière}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Parallèle avec l'exemple de la prévision saisonnière}
Si on fait le parallèle avec les exemples de l'exemple "prévisions saisonnières (c.f. tableau \ref{exemples prévision saisonnière}) et ceux de notre solution (c.f. tableau \ref {tab: Structure de la base de données d'exemples pour l'entrainement du SVM}), on observe que dans les deux cas les données sont structurées en exemples et features. Cependant, dans la solution que l'on propose, les données de chaque exemple évoluent temporellement (e.g. la "HipPitchPositionSensorValue" de l'exemple 1 correspond à la colonne "HipPitchPositionSensorValue" du fichier $log_1$ qui a une évolution temporelle), alors que celles de la prévision saisonnière sont discrètes (e.g la température de l'exemple 1 est de -10\degres C, elle est discrète ) \\
Le problème est qu'on ne peut réaliser de l'apprentissage supervisé qu'avec des données discrètes. Sous leurs formes actuelles, les données de nos exemples ne peuvent donc pas servir à entrainer les algorithmes SVM de nos couches root cause. Une solution sera soumise ultérieurement en partie \ref{Automatisation du processus d'investigation: Solutions testées}


\subsection{Le modèle d'apprentissage}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Le modèle d'apprentissage}
Le modèle d'apprentissage utilisé est le Support Vector Machine (SVM) avec l'utilisation de Kernels (c.f. présentation de l'algorithme partie \ref{Le Machine Learning: Les différents algorithmes: SVM}).


\subsection{La décision}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: La décision}
Chaque couche root cause délivre en sortie la probabilité que la root cause à laquelle elle est rattachée soit présente dans le fichier log analysé (via le SVM).



\section{Reconnaissance de motifs}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs}
On souhaite réaliser de la reconnaissance de motifs grâce à l'utilisation du Machine Learning, afin de mettre en place l'automatisation du processus d'investigation. L'utilisation de cette méthode répond notamment au problème causé par l'évolution temporelle des exemples utilisés pour l'entraînement de notre système (c.f. partie \ref{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Parallèle avec l'exemple de la prévision saisonnière}). On présente dans cette partie les différentes solutions envisagées et les raisons ayant amené à utiliser la reconnaissance de motifs. \\

Afin de simplifier le développement du système de reconnaissance de motifs, on admet dans un premier temps que chaque couche root cause est un système d'apprentissage automatique capable d'apprendre uniquement à détecter une root cause en analysant une seule feature (e.g. BaseAccZ, HipPitchSensorValue, etc.) 

\subsection{Différentes approches étudiées}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées}
L'évolution temporelle des exemples utilisés pour l'entraînement de l'algorithme implique de prétraiter les données (c.f. partie \ref{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Parallèle avec l'exemple de la prévision saisonnière}). Pour cela, différentes approches sont envisagées.

\subsubsection{Création de nouvelles features}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées: Création de nouvelles features}
On propose de créer de nouvelles features, constantes, caractéristiques des features actuelles. Dans le cadre de cette étude, on les identifiera sous l'appellation de \emph{caractéristiques simplifiées}. On peut par exemple calculer la moyenne d'une feature, sa valeur crête-à-crête, sa valeur maximum, etc. On se sert ensuite de ces nouvelles caractéristiques simplifiées pour réaliser l'entrainement de notre algorithme d'apprentissage automatique (c.f. exemple figure \ref{fig:Calcul de nouvelles features}).

\begin{figure}[h]
	\centering\includegraphics[height=8cm]{images/caracteristiques_simples_1.png}
	\caption[Calcul des caractéristiques simplifiées]{Calcul des caractéristiques simplifiées. Les figures a) et b) représentent respectivement l'évolution de la valeur du senseur et de l'actuateur de la hanche au cours du temps, lors de la chute d'un robot. La ligne rouge représente la valeur moyenne de chacune des features. la ligne noire correspond à la valeur crête-à-crête de chacune des features. On a ainsi réduit nos features à deux valeurs constantes. On peut donc entraîner l'algorithme d'apprentissage automatique à partir de ces caractéristiques simplifiées.}
	\label{fig:Calcul de nouvelles features}
\end{figure}

Le problème de cette approche est qu'elle réduit le nombre d'informations que contient une donnée à seulement quelques caractéristiques (e.g. moyenne et valeur crête-à-crête). Comme le démontre la figure \ref{fig:Comparaison de deux caractéristiques}, cette diminution des informations peut entrainer des risques de confusion entre différentes features, i.e. deux features différentes peuvent avoir les mêmes caractéristiques. Or, si on souhaite utiliser cette approche dans l'architecture que l'on propose partie \ref{Automatisation du processus d'investigation: Achitecture High Level du système proposé}, le risque est que deux couches root cause soient liées à des features dont les caractéristiques sont similaires. Dans ce cas, le système est incapable de déterminer quelle root cause est responsable de l'apparition d'un error name.

\begin{figure}[h]
	\centering\includegraphics[height=8cm]{images/caracteristiques_simples_2.png}
	\caption[Comparaison de deux caractéristiques]{Calcul de nouvelles features. On retrouve sur la figure a) les valeurs du senseur et de l'actuateur de la hanche, ainsi que leurs caractéristiques simplifiées. Sur la figure b), on observe deux autres features et leurs caractéristiques simplifiées. On remarque que, bien qu'il s'agisse de features différentes entres les figures a) et b), ces derniers possèdent les mêmes caractéristiques simplifiées.}
	\label{fig:Comparaison de deux caractéristiques}
\end{figure}

\subsubsection{Considérer chaque unité de temps comme une feature}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées: Considérer chaque unité de temps comme une feature}
On propose de considérer chaque unité de temps comme une feature caractéristique de nos différents exemples. Le nombre d'entrées du système d'apprentissage automatique est donc égal au nombre d'échantillons contenus dans une donnée temporelle (c.f. figure \ref{fig:Considérer chaque unité de temps comme une feature: exemple}). \\
De manière intuitive: \\
Chaque feature peut être associée à deux formes distinctives: 
\begin{itemize}
	\item Une forme "normale" de la courbe, i.e. une feature qui n'est pas liée à une root cause.  
	\item Une forme caractéristique de la courbe, attestant de la présence d'une root cause. 
\end{itemize}

Entrainer le modèle revient à créer un patron représentatif de la feature liée à la présence d'une root cause. Pour cela, on entraîne l'algorithme d'apprentissage automatique à partir des deux formes distinctes. Cela revient à apprendre la forme globale et caractéristique d'une feature en cas de présence ou non d'une root cause. Une fois cette forme apprise, on la compare avec la feature que l'on souhaite analyser afin de savoir si la root cause est présente ou non dans la feature. \\
Par exemple, on souhaite créer une nouvelle couche root cause (i.e. entraîner un algorithme d'apprentissage) à reconnaitre le frottement des freins de la hanche, entraînant la chute du robot durant le Filtering Test. Pour cela on va s'intéresser plus particulièrement à la courbe de 

\begin{figure}[h]
	\centering\includegraphics[height=8cm]{images/unit_tps_feature.png}
	\caption[Considérer chaque unité de temps comme une feature: exemple]{Considérer chaque unité de temps comme une feature: exemple. On souhaite dans cet exemple entraîner l'algorithme à reconnaitre le .}
	\label{fig:Considérer chaque unité de temps comme une feature: exemple}
\end{figure}

\subsubsection{Passage des données dans le domaine fréquentiel}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées: Passage des données dans le domaine fréquentiel}
Afin de supprimer l'aspect temporel des exemples, on propose de les passer dans le domaine fréquentiel. A la manière de la solution testée en partie \ref{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées: Considérer chaque unité de temps comme une feature} Chaque valeur fréquentielle devient alors une entrée de notre système, i.e. une feature. \\

Par exemple, on calcule la $fft$ des valeurs de l'accélération en $Z$ lors de la chute d'un robot.  

\subsubsection{Calcul de la convolution}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées: Calcul de la convolution}

\subsection{Concept}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Concept}


\section{Étendre le problème à plusieurs dimensions }
\label{Automatisation du processus d'investigation: Étendre le problème à plusieurs dimensions}





\section{Difficultés notoires rencontrées}
\label{Automatisation du processus d'investigation: Difficultés notoires rencontrées}




\section{Performances de la solution}
\label{Automatisation du processus d'investigation: Performances de la solution}
Une fois l'architecture du système définie, on souhaite mesurer les performances de l'algorithme . Il existe pour cela plusieurs outils relatifs au Machine Learning.

\subsection{Optimisation des paramètres du SVM}
\label{Industrialisation du produit: Performances de la solution:Optimisation des paramètres du SVM}
La prise de décision de la part de l'algorithme du SVM peut être contrôlé via deux paramètres: C et gamma.
\begin{description}
	\item [gamma] 
	\item [C]
\end{description}

Afin de déterminer la meilleur combinaison de valeurs des deux paramètres, on calcule les \emph{courbes de validation}. Cela consiste à faire varier chacun des deux paramètres sur une plage de données et à calculer la précision de l'algorithme pour chaque valeur. On conserve la valeur optimale. 

\subsection{Matrices de confusion}
\label{Industrialisation du produit: Performances de la solution:Matrices de confusion}

\subsection{Courbes d'apprentissage}
\label{Industrialisation du produit: Performances de la solution:Courbes d'apprentissage}