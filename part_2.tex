\chapter{Automatisation du processus d'investigation}
\label{Automatisation du processus d'investigation}
\thispagestyle{fancy}
Lorsqu'une \emph{error name} est révélée durant le Filtering test, de nombreuses données sont enregistrées dans un fichier journal (que l'on retrouve plus souvent sous le terme anglais de fichier "log".) Une analyse poussée de ces informations permet de déterminer la \emph{root cause} liée à l'\emph{error name} (partie \ref{Introduction:Expression du besoin:Hiérarchisation des erreurs}). Afin d'automatiser ce processus d'analyse, on s'appuie sur l'utilisation d'algorithmes d'apprentissage automatique. 

\section{Architecture High Level du système proposé}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé}
L'architecture haut niveau de la solution que l'on propose est composée de deux couches: une couche \emph{root cause} et une couche \emph{error name}.
\begin{description}
	\item [Couche root cause] La couche \emph{root cause} permet de détecter la présence d'une \emph{root cause} dans le fichier log que l'on analyse. Il s'agit d'un algorithme d'apprentissage automatique entraîné à effectuer cette tâche.
	\item [Couche error name] La couche \emph{error name} est constituée d'un ensemble de couches \emph{root cause} de telle manière que lorsqu'un fichier log est mis en entrée du système, l'ensemble des couches \emph{root cause} sont activées. Ainsi, le système recherche la présence de chaque \emph{root cause} connue dans l'exemple étudié. On dit que les \emph{root causes} sont liées à l'\emph{error name}. On obtient en sortie de la couche \emph{error name} le nom de la \emph{root cause} ayant la plus forte probabilité d'avoir été reconnue.
\end{description} 

\subsubsection{Exemple de mise en place  d'une couche error name et de ses couches root cause}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Exemple de mise en place  d'une couche error name et de ses couches root cause}
Afin d'exposer de manière concrète le fonctionnement de l'architecture haut niveau de la solution proposée, on soumet un exemple de mise en place d'une architecture de détection et son utilisation. \\

\paragraph{Mise en place du système de détection d'une root cause}
On souhaite dans un premier temps mettre en place l'architecture permettant de détecter la cause (\emph{root cause}) ayant entrainé la chute du robot lors du Filtering test (\emph{error name}). Cette étape consiste à créer les couches \emph{root cause}, i.e. entrainer différents algorithmes d'apprentissage automatique à reconnaître la \emph{root cause} pour laquelle ils ont été créés (figure \ref{fig:Creation des couches root cause}). Afin d'entraîner ces couches, on utilise les données utiles à chaque \emph{root cause}, contenues dans le fichier log généré lors de la chute d'un robot durant le Filtering Test. Par exemple, dans le cas de la \emph{root cause} "frottement des freins de la hanche", on utilisera les données "valeurs du senseur de la hanche" et "valeurs de l'actuateur de la hanche". Ces deux éléments correspondent aux features de notre système d'apprentissage (c.f. partie \ref{Le Machine Learning: Généralités sur le Machine Learning: Définition et principe général:Lexique}). L'ensemble de ces couches \emph{root cause} sont liées une couche \emph{error name}, ici la chute d'un robot.

\begin{figure}[h]
	\centering\includegraphics[height=7cm]{images/synoptique_root.png}
	\caption[Création des couches root cause]{Synoptique haut niveau de la création des couches \emph{root cause}. Les couches \emph{root cause} correspondent à des algorithmes d'apprentissage automatique que l'on entraîne à détecter la \emph{root cause} à laquelle ils sont associés. Par exemple, créer la couche \emph{root cause} "frottement du frein de la hanche" revient à entraîner un algorithme d'apprentissage de type SVM, à partir des valeurs senseurs et actuateurs de la hanche des fichiers logs.}
	\label{fig:Creation des couches root cause}
\end{figure}

\paragraph{Utilisation du système de détection d'une root cause}
Une fois nos différentes couches \emph{root cause} créées, on souhaite utiliser notre système pour détecter la cause ayant entrainé la chute d'un robot (cf. figure \ref{fig:utilisation de la couche error name}). Pour cela, on place à l'entrée de notre couche \emph{error name} le fichier log que l'on souhaite analyser. Chaque couche \emph{root cause} extrait de ce fichier les features qui lui sont liées (e.g. la \emph{root cause} "frottement des freins de la hanche" est liée aux features senseurs et actuateurs de la hanche). L'algorithme SVM de chaque couche \emph{root cause} va alors émettre une décision quant à la présence ou non de leur \emph{root cause} dans le fichier log. Cette décision correspond à la probabilité que la \emph{ root cause} ait été détectée (en \%). La couche \emph{root cause} ayant la probabilité la plus élevée en sortie est considérée comme la \emph{root cause} ayant entrainé l'\emph{error name},  ici la chute du robot) 

\begin{figure}[h]
	\centering\includegraphics[width=15cm]{images/synoptique_error.png}
	\caption[Utilisation de la couche error name]{Synoptique haut niveau de l'utilisation de la couche \emph{error name}. La couche \emph{error name} contient plusieurs couches \emph{root cause} (on dit qu'elles sont liées). On met en entrée du système le fichier log que l'on souhaite analyser, puis chaque couche \emph{root cause} va détecter la présence de sa \emph{root cause}. On obtient en sortie de la couche \emph{error name} la \emph{root cause}  ayant eu la plus forte probabilité d'avoir été reconnue.}
	\label{fig:utilisation de la couche error name}
\end{figure}

Chaque couche \emph{root cause} peut être considérée comme un système d'apprentissage à part entière. Le schéma fonctionnel d'une \emph{root cause} (cf. figure 	\ref{fig:Synoptique d'une couche root cause}) reprend la même structure que celui du Machine Learning (cf. figure \ref{fig:Schéma fonctionnel haut niveau du Machine Learning}). En effet, chaque \emph{root cause} est constituée d'une instance de l'algorithme SVM. Dans la suite de notre étude de l'architecture haut niveau, on s'intéressera plus particulièrement  au fonctionnement de la couche \emph{root cause}, celle-ci contenant l'ensemble du traitement et de l'analyse des données.

\begin{figure}[h]
	\centering\includegraphics[height=7cm]{images/exemple_root.png}
	\caption[Synoptique d'une couche root cause]{Synoptique d'une couche \emph{root cause}. Il correspond à celui du Machine Learning car chaque couche \emph{root cause} est en réalité un algorithme d'apprentissage supervisé SVM que l'on entraine à détecter une \emph{root cause} particulière.}
	\label{fig:Synoptique d'une couche root cause}
\end{figure}

\subsection{Les exemples}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples}
Les exemples sont les éléments permettant d'entraîner un algorithme d'apprentissage automatique (cf. partie \ref{Le Machine Learning: Généralités sur le Machine Learning: Les données}). Dans le cadre de la résolution de notre problématique, ils correspondent aux données générées et enregistrées dans le fichier log lorsqu'une erreur (\emph{error name}) est détectée durant le Filtering Test.

\subsubsection{Structure du fichier log}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Structure du fichier log}
Le fichier log renferme un ensemble de données enregistrées lors de la détection d'une erreur durant le Filtering Test. Elles correspondent aux "rythmes vitaux" du robot. Le fichier contient par exemple l'évolution temporelle des différents actuateurs et senseurs de Pepper, la température de différentes pièces mécaniques, etc. Dans le cadre de l'entraînement de l'algorithme du Machine Learning (SVM), chacune de ces constantes correspond à une feature  (cf. partie  \ref{Le Machine Learning: Généralités sur le Machine Learning: Définition et principe général:Lexique}). Soit le tableau \ref {tab: Extrait du contenu d'un fichier log}, un extrait du contenu d'un fichier log:

\begin{equation}
\begin{blockarray}{ccccccc}
\begin{block}{c[cccccc]}
features & X_1 & X_2 & X_3 & X_4 &  X_5 & X_6 \\
t_0 & -0,404 & 0,64 & -0,023 & -0,04 & -0,008 & -0,007 \\
t_1 & -0,404 & 0,64 & -0,029 & -0,038 & -0,006 & -0,006 \\
t_3 & -0,404 & 0,576 & -0,029 & -0,033 & -0,008 & -0,012 \\
t_4 & -0,402 & 0,544 & -0,029 & -0,027 & -0,012 & -0,022 \\
t_5 & -0,401 & 0,448 & -0,029 & -0,027 & -0,015 & -0,029 \\
t_6 & -0,401 & 0,448 & -0,023 & -0,029 & -0,017 & -0,031 \\
t_7 & -0,408 & 0,096 & -0,021 & -0,031 & -0,015 & -0,032 \\
t_8 & -0,444 & 0,096 & -0,021 & -0,032 & -0,015 & 0,035 \\
t_9 & -0,486 & 0,096 & -0,021 & -0,033 & -0,017 & -0,039 \\
t_{10} & -0,523 & 0,128 & -0,021 & -0,033 & -0,018 & -0,043 \\
t_n & ... & ... & ... & ... & ... & ... \\
\end{block}
\end{blockarray}
\label {tab: Extrait du contenu d'un fichier log}
\end{equation}

Avec :
\begin{itemize}
	\item $X_1$ = HeadPitchPositionActuatorValue
	\item $X_2$ = HeadPitchElectricCurrentSensorValue
	\item $X_3$ = ipPitchPositionSensorValue
	\item $X_4$ = HipPitchPositionActuatorValue
	\item $X_5$ = KneePitchPositionSensorValue
	\item $ X_6$ = KneePitchPositionActuatorValue
\end{itemize}

Le fichier log, représenté par le tableau \ref {tab: Extrait du contenu d'un fichier log}, correspond à un exemple de la base de données qui sert à entrainer chacun de nos algorithmes. \\ 
A chaque colonne du tableau correspond une feature. Chacune des lignes est la valeur des features à un instant t (une ligne ne correspond pas à un exemple !). 

\subsubsection{Structure de la base de données d'exemples}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Structure de la base de données d'exemples}
La base de données est composée de plusieurs exemples qui correspondent à des fichiers logs. Par exemple, dans le cadre de la construction de couche \emph{error name} de la chute d'un robot, la base de données sera constituée de fichiers logs générés par plusieurs cas de chutes sur différents robots. On peut représenter la structure des données de la base de données par le tableau \ref {tab: Structure de la base de données d'exemples pour l'entrainement du SVM}

\begin{equation}
\begin{blockarray}{ccccccc}
\begin{block}{c[cccccc]}
features & X_1 & X_2 & X_3 & X_4 &  X_5 & X_6 \\
exemple_0 & log_0 [X_1] & log_0 [X_2] & log_0 [X_3]& log_0 [X_4] & log_0 [X_5] & log_0 [X_6]  \\
exemple_1 & log_1 [X_1] & log_1 [X_2] & log_1 [X_3]& log_1 [X_4] & log_1 [X_5] & log_1 [X_6]  \\
exemple_2 & log_2 [X_1] & log_2 [X_2] & log_2 [X_3]& log_2 [X_4] & log_2 [X_5] & log_2 [X_6]  \\
exemple_3 & log_3 [X_1] & log_3 [X_2] & log_3 [X_3]& log_3 [X_4] & log_3 [X_5] & log_3 [X_6]  \\
exemple_4 & log_4 [X_1] & log_4 [X_2] & log_4 [X_3]& log_4 [X_4] & log_4 [X_5] & log_4 [X_6]  \\
exemple_4 & log_4 [X_1] & log_n [X_2] & log_n [X_3]& log_n [X_4] & log_n [X_5] & log_n [X_6]  \\
\end{block}
\end{blockarray}
\label {tab: Structure de la base de données d'exemples pour l'entrainement du SVM}
\end{equation}

Tout comme la structure d'un fichier log (\ref{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Structure du fichier log}), chaque colonne correspond à une feature. Chaque ligne de ce tableau représente un exemple et correspond à un fichier log. Cela signifie que chaque ligne du tableau correspond au contenu d'un fichier log, présenté dans le tableau \ref {tab: Extrait du contenu d'un fichier log}.

\subsubsection{Construction d'une couche root cause à partir de la base de données d'exemples}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Construction d'une couche root cause à partir de la base de données d'exemples}
Lorsque l'on veut construire une nouvelle couche \emph{root cause}, i.e. entraîner un nouvel algorithme d'apprentissage, pour détecter la présence d'une \emph{root cause} particulière dans un fichier log, on sélectionne uniquement les features de la base de données d'exemples liées à celle-ci. Par exemple, si on veut créer une nouvelle couche root cause "frottement des freins de la hanche" (lié à l'error name chute du robot), on n'utilisera que les features "HipPitchPositionSensorValue" et "HipPitchPositionActuatorValue" de notre base de données.

\subsubsection{Représentation des exemples et des classes}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Représentation des exemples et des classes}
Pour construire chaque couche \emph{root cause}, on doit entrainer l'algorithme de l'apprentissage automatique SVM. Pour cela, on a besoin d'exemples labellisés positif (dans notre cas, le terme positif signifie que l'exemple est le motif caractéristique de la \emph{root cause}) et des exemples labellisés négatif (des exemples qui ne correspondent pas au motif caractéristique de la \emph{root cause}). Ces deux groupes de données forment alors des classes. \\
Dans le cadre de la \emph{root cause} "frottement des freins de la hanche", on peut visualiser l'ensemble des exemples et des classes dans un repère construit à partir des features "position du senseur de la hanche" (clé HipPitchPositionSensorValue) et "position de l'actuateur de la hanche" (clé HipPitchPositionActuatorValue) en figure \ref{fig:Représentation de la répartition des exemples et des classes en fonction des features}. Lors de la phase d'investigation, l'algorithme emet alors un choix entre ces deux classes: positive, i.e. présence de la \emph{root cause} dans le fichier log, négative, i.e. absence de la \emph{root cause} dans le fichier log. 

\begin{figure}[h]
	\centering\includegraphics[width=9cm]{images/classes_log.png}
	\caption[Représentation de la répartition des exemples et des classes en fonction des features]{Représentation de la répartition des exemples et des classes en fonction des features. On observe que lorsque l'on visualise les exemples contenus dans nos fichiers logs en fonction des deux features HipPitchPositionSensorValue et HipPitchPositionActuatorValue, ces derniers se regroupent en deux zones homogène qui forment nos classes. Une classe correspond aux exemples de \emph{root cause} "frottement des freins de la hanche", l'autre classe aux exemple qui ne correspondent pas à des exemples de "frottement des freins de la hanche".
	\label{fig:Représentation de la répartition des exemples et des classes en fonction des features}
\end{figure}

Cette représentation n'est pas fonctionnelle mais conceptuelle, i.e. qu'il ne s'agit pas d'une visualisation résultant d'un système fonctionnel mais d'une idée haut niveau que l'on a de la sortie de notre système. 


\subsubsection{Parallèle avec l'exemple de la prévision saisonnière}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Parallèle avec l'exemple de la prévision saisonnière}
Si on compare les échantillons utilisés dans l'exemple "prévision saisonnière" (cf. tableau \ref{exemples prévision saisonnière}) et ceux de notre solution (c.f. tableau \ref {tab: Structure de la base de données d'exemples pour l'entrainement du SVM}), on observe que dans les deux cas les données sont structurées en exemples et features. Cependant, dans la solution que l'on propose, les données de chaque exemple évoluent temporellement (e.g. la "HipPitchPositionSensorValue" de l'exemple 1 correspond à la colonne "HipPitchPositionSensorValue" du fichier $log_1$, qui a une évolution temporelle), alors que celles de la prévision saisonnière sont discrètes (e.g la température de l'exemple 1 est de -10\degres C, elle est discrète) \\
Or, on ne peut pas réaliser de l'apprentissage supervisé avec des données temporelles. Sous leurs formes actuelles, nos exemples ne peuvent donc pas servir à entrainer les algorithmes SVM de nos couches \emph{root cause}.


\subsection{Le modèle d'apprentissage}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Le modèle d'apprentissage}
Le modèle d'apprentissage utilisé est le Support Vector Machine (SVM) (cf. partie \ref{Le Machine Learning: Les différents algorithmes: SVM}).


\subsection{La décision}
\label{Automatisation du processus d'investigation: Achitecture High Level du système proposé: La décision}
Chaque couche \emph{root cause} délivre en sortie la probabilité que la \emph{root cause} à laquelle elle est rattachée soit présente dans le fichier log analysé (via le SVM).



\section{Détection d'une root cause}
\label{Automatisation du processus d'investigation: Détection d'une root cause}
On souhaite réaliser de la reconnaissance de motifs grâce à l'utilisation du SVM, pour détecter la présence d'une \emph{root cause} dans un fichier log. L'utilisation de cette méthode répond notamment au problème causé par l'évolution temporelle des exemples utilisés pour l'entraînement de l'algorithme (cf. partie \ref{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Parallèle avec l'exemple de la prévision saisonnière}). On présente dans cette partie les différentes solutions envisagées et les raisons ayant amené à utiliser la reconnaissance de motifs. \\

\subsection{Différentes approches étudiées}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées}
L'évolution temporelle des exemples utilisés pour l'entraînement de l'algorithme implique de prétraiter les données (cf. partie \ref{Automatisation du processus d'investigation: Achitecture High Level du système proposé: Les exemples: Parallèle avec l'exemple de la prévision saisonnière}). Pour cela, différentes approches sont envisagées.

\subsubsection{Création de nouvelles features}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées: Création de nouvelles features}
On propose de créer de nouvelles features constantes. Elles sont des caractéristiques des features actuelles. Dans le cadre de cette étude, on les identifiera sous l'appellation de \emph{caractéristiques simplifiées}. Elles correspondent par exemple au calcul de la moyenne d'une feature, la valeur crête-à-crête, la valeur maximum, etc. On se sert ensuite de ces  \emph{caractéristiques simplifiées} pour réaliser l'entrainement de l'algorithme d'apprentissage automatique (cf. exemple figure \ref{fig:Calcul de nouvelles features}).

\begin{figure}[h]
	\centering\includegraphics[width=12cm]{images/caracteristiques_simples_1.png}
	\caption[Calcul des caractéristiques simplifiées]{Calcul des \emph{caractéristiques simplifiées}. La figure représente l'évolution de la feature "accélération du robot selon l'axe $z$",  caractéristique de la chute d'un robot. La ligne rouge représente sa valeur moyenne. la ligne noire correspond à sa valeur crête-à-crête. On a ainsi réduit notre feature à deux valeurs constantes. On peut  entraîner l'algorithme d'apprentissage automatique à partir de ces \emph{caractéristiques simplifiées}.}
	\label{fig:Calcul de nouvelles features}
\end{figure}

Le problème de cette approche est qu'elle réduit le nombre d'informations que contient une donnée à seulement quelques features (e.g. moyenne, valeur crête-à-crête). Comme le démontre la figure \ref{fig:Comparaison de deux caractéristiques}, cette diminution des informations peut entrainer des risques de confusion entre différentes features, i.e. deux features différentes peuvent avoir les mêmes caractéristiques. Or, si on souhaite utiliser cette approche dans l'architecture que l'on propose (cf. partie \ref{Automatisation du processus d'investigation: Achitecture High Level du système proposé}), le risque est que deux couches \emph{root cause} soient liées à des features dont les caractéristiques sont similaires. Dans ce cas, le système est incapable de déterminer quelle \emph{root cause} est responsable de l'apparition d'une \emph{error name}.

\begin{figure}[h]
	\centering\includegraphics[width=15cm]{images/caracteristiques_simples_2.png}
	\caption[Comparaison de deux caractéristiques]{Comparaison de deux caractéristiques. On retrouve sur la figure a) la valeur de l'accélération selon l'axe $z$ et ses caractéristiques simplifiées. Sur la figure b), on observe une autre feature et ses caractéristiques simplifiées. On remarque que, bien qu'il s'agisse de features différentes entres les figures a) et b), ces dernières possèdent les mêmes \emph{caractéristiques simplifiées}.}
	\label{fig:Comparaison de deux caractéristiques}
\end{figure}

\subsubsection{Considérer chaque unité de temps comme une feature}
\label{Automatisation du processus d'investigation: Reconnaissance de motifs: Différentes approches étudiées: Considérer chaque unité de temps comme une feature}
On propose de considérer chaque unité de temps comme une feature. Le nombre d'entrées du système d'apprentissage automatique est donc égal au nombre d'échantillons contenus dans un exemple. \\
De manière intuitive, entrainer le modèle revient à créer un patron représentatif de la feature lorsque celle-ci est liée à la présence d'une \emph{root cause}. Une fois cette forme apprise, on la compare avec la feature que l'on souhaite analyser afin de savoir si la \emph{root cause} est présente ou non dans la feature.
\newline

